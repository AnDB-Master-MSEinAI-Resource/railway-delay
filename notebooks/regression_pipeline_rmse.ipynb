{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "563e6fed",
   "metadata": {},
   "source": [
    "# Dự báo Định lượng Trễ Tàu — Regression Pipeline (Tối ưu RMSE)\n",
    "\n",
    "Mục tiêu: Xây dựng pipeline hồi quy dự đoán `DELAY_MINUTES` tối ưu cho RMSE. Notebook bao gồm: tiền xử lý dữ liệu, EDA, feature engineering (lag, rolling mean, cyclical time), validation thời gian, baseline, RandomForest, XGBoost/LightGBM, tuning và lưu mô hình.\n",
    "\n",
    "Paths (Được sử dụng trong notebook):\n",
    "- DATATRAIN = `D:\\MSE\\5. Data Mining\\railway-delay\\data\\processed\\merged_train_data.csv`\n",
    "- DATATEST = `D:\\MSE\\5. Data Mining\\railway-delay\\data\\raw\\railway-delay-dataset.csv`\n",
    "\n",
    "> Lưu ý: Notebook được thiết kế để chạy trên dữ liệu đầy đủ, nhưng nếu bộ nhớ hệ thống hạn chế, hãy bật tùy chọn `DOWNSAMPLE = True` để thực hiện thử nghiệm nhanh."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a6f869",
   "metadata": {},
   "source": [
    "## 1. Giới thiệu tổng quan\n",
    "\n",
    "Bài toán: Dự đoán độ trễ (`DELAY_MINUTES`) để hỗ trợ tối ưu vận hành, giảm thiểu rủi ro và nâng cao trải nghiệm khách hàng. Mục tiêu chính là giảm RMSE trên tập kiểm thử bằng pipeline: Tiền xử lý, tạo feature, training (XGBoost / LightGBM), tuning, và triển khai.\n",
    "\n",
    "Tóm tắt các bước trong notebook:\n",
    "1. Setup môi trường, đọc dữ liệu.\n",
    "2. Load và kiểm tra nhanh dữ liệu.\n",
    "3. Tiền xử lý (missing values, loại bỏ outliers, winsorization, chuẩn hóa).\n",
    "4. EDA: Histogram/KDE, Boxplot, Heatmap, phân tích theo thời gian.\n",
    "5. Tạo feature: cyclical time, lag, rolling mean, tương tác (weather, distance*stops).\n",
    "6. Training: baseline (mean, linear), random forest, XGBoost/LightGBM; TimeSeriesSplit cho validation.\n",
    "7. So sánh mô hình và kết luận (RMSE là chỉ số chính).\n",
    "\n",
    "Lưu ý: Nếu dataset lớn, bật `DOWNSAMPLE = True` để thử nghiệm nhanh trước khi chạy full pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9493a1cb",
   "metadata": {},
   "source": [
    "## Workflow Plan\n",
    "\n",
    "This notebook follows the following structure to operationalize railway delay prediction:\n",
    "\n",
    "1. **Introduction** (background, motivations, and project objectives).\n",
    "2. **Data Description** (dataset overview and metadata, ensuring we understand inputs before modeling).\n",
    "3. **Data Preprocessing** (missing handling, encoding, feature creation, scaling, and train/test splitting).\n",
    "4. **Exploratory Data Analysis** (distributions, correlations, temporal patterns, and PCA to guide modeling choices).\n",
    "5. **New Features & Evaluation Metrics** (proposed engineered features plus balanced/ROC/F2 metrics to handle imbalance).\n",
    "6. **Model Training & Evaluation** (baselines, tree ensembles, optional SVM/KNN/Naive Bayes, time-aware CV, and tuning).\n",
    "7. **Comparison & Recommendations** (contrast models with past results, record improvements, highlight SHAP insights, and suggest deployment next steps).\n",
    "\n",
    "Each subsequent section in the notebook aligns with this plan and records its outputs in the shared `RESULTS` log for easy comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2151e48f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac55267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\AnDB\\L\\mse\\railway-delay\\notebooks\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m sys.path.append(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mD:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mMSE\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m5. Data Mining\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mrailway-delay\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Import helper functions\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeature_helpers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compute_prev_delay_safe, compute_rolling_features_safe\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Paths\u001b[39;00m\n\u001b[32m     17\u001b[39m DATATRAIN = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mD:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mAnDB\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mL\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mmse\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mrailway-delay\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mdocs\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mmerged_train_data.csv\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "# Section 1: Setup\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "print(os.getcwd())\n",
    "\n",
    "# Add project root to sys.path to import custom modules\n",
    "import sys\n",
    "sys.path.append(r\"D:\\AnDB\\L\\mse\\railway-delayy\")\n",
    "\n",
    "# Import helper functions\n",
    "from src.utils.feature_helpers import compute_prev_delay_safe, compute_rolling_features_safe\n",
    "\n",
    "# Paths\n",
    "DATATRAIN = r\"D:\\AnDB\\L\\mse\\railway-delay\\docs\\merged_train_data.csv\"\n",
    "DATATEST = r\"D:\\AnDB\\L\\mse\\railway-delay\\docs\\merged_train_data.csv\"\n",
    "MODEL_DIR = os.path.join(os.getcwd(), \"models\")\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_STATE = 42\n",
    "import numpy as np\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Dependency imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Utility to install and import packages in notebook reliably\n",
    "import importlib\n",
    "import subprocess\n",
    "\n",
    "# Toggle to allow the notebook to pip-install optional packages at runtime (opt-in)\n",
    "AUTO_INSTALL = True\n",
    "\n",
    "# Ensure secure and controlled install behavior\n",
    "def install_and_import(pkg_name, import_name=None, extras=None):\n",
    "    import_name = import_name or pkg_name\n",
    "    try:\n",
    "        return importlib.import_module(import_name)\n",
    "    except Exception:\n",
    "        if not AUTO_INSTALL:\n",
    "            print(f\"Package {pkg_name} not found and AUTO_INSTALL is False. Skipping install.\")\n",
    "            return None\n",
    "        try:\n",
    "            pkg_install = pkg_name if extras is None else f\"{pkg_name}{extras}\"\n",
    "            print(f\"Installing {pkg_install}...\")\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg_install])\n",
    "            return importlib.import_module(import_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to install or import {pkg_name}: {e}\")\n",
    "            return None\n",
    "\n",
    "# Install and import XGBoost for GPU support\n",
    "# Try local conda first for GPU support, fallback to pip\n",
    "xgb = None\n",
    "conda_path = os.path.join(os.getcwd(), \"miniconda\", \"Scripts\", \"conda.exe\")\n",
    "if os.path.exists(conda_path):\n",
    "    try:\n",
    "        result = subprocess.run([conda_path, '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(\"Local conda detected, installing XGBoost with GPU support via conda...\")\n",
    "            # Use conda to install XGBoost with GPU support\n",
    "            subprocess.check_call([conda_path, 'install', '-c', 'conda-forge', 'xgboost', '-y'])\n",
    "            # Try to import from conda environment\n",
    "            # Add conda to PATH temporarily\n",
    "            conda_bin = os.path.join(os.getcwd(), \"miniconda\", \"Scripts\")\n",
    "            env = os.environ.copy()\n",
    "            env['PATH'] = conda_bin + os.pathsep + env['PATH']\n",
    "            # Try importing xgboost\n",
    "            try:\n",
    "                import sys\n",
    "                sys.path.insert(0, os.path.join(os.getcwd(), \"miniconda\", \"Lib\", \"site-packages\"))\n",
    "                xgb = __import__('xgboost')\n",
    "                print(\"XGBoost imported from conda environment\")\n",
    "            except ImportError:\n",
    "                print(\"Failed to import XGBoost from conda, falling back to pip\")\n",
    "                xgb = install_and_import('xgboost')\n",
    "        else:\n",
    "            raise Exception(\"Conda not working\")\n",
    "    except Exception as e:\n",
    "        print(f\"Conda install failed ({e}), falling back to pip install...\")\n",
    "        xgb = install_and_import('xgboost')\n",
    "else:\n",
    "    print(\"Local conda not found, falling back to pip install...\")\n",
    "    xgb = install_and_import('xgboost')\n",
    "\n",
    "if xgb:\n",
    "    from xgboost import XGBRegressor\n",
    "else:\n",
    "    print(\"XGBoost not available, falling back to CPU models\")\n",
    "    XGBRegressor = None\n",
    "\n",
    "# Verbose flag for toggling notebook prints\n",
    "VERBOSE = True\n",
    "\n",
    "# Downsample flag for memory-aware loading\n",
    "DOWNSAMPLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd4a85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Training Setup\n",
    "# Check if GPU is available for XGBoost\n",
    "def gpu_available():\n",
    "    try:\n",
    "        import xgboost as xgb\n",
    "        import pandas as pd\n",
    "        # Try to fit a small model with GPU\n",
    "        X_test = pd.DataFrame({'a': [1,2,3]})\n",
    "        y_test = [1,2,3]\n",
    "        test_reg = xgb.XGBRegressor(tree_method='gpu_hist', n_estimators=1, max_depth=1)\n",
    "        test_reg.fit(X_test, y_test)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"GPU not available: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"GPU available for XGBoost:\", gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a554ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test GPU training with a small sample\n",
    "if XGBRegressor is not None:\n",
    "    print(\"Testing XGBoost training...\")\n",
    "    import pandas as pd\n",
    "    # Create a small dummy dataset\n",
    "    X_test = pd.DataFrame({'feature1': [1,2,3,4,5], 'feature2': [5,4,3,2,1]})\n",
    "    y_test = [1,2,3,4,5]\n",
    "    \n",
    "    # Fit a quick model\n",
    "    tree_method = 'gpu_hist' if gpu_available() else 'hist'\n",
    "    test_model = XGBRegressor(tree_method=tree_method, n_estimators=10, random_state=RANDOM_STATE)\n",
    "    test_model.fit(X_test, y_test)\n",
    "    print(f\"XGBoost training test successful with tree_method='{tree_method}'!\")\n",
    "else:\n",
    "    print(\"XGBoost not available for testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27646fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "\n",
    "## Section 2: Load Data (Train & Test)\n",
    "\n",
    "\n",
    "# Attempt to read a sample to infer columns & dtypes\n",
    "sample_nrows = 5000\n",
    "try:\n",
    "    train_sample = pd.read_csv(DATATRAIN, nrows=sample_nrows)\n",
    "    print(\"Train sample loaded. Shape:\", train_sample.shape)\n",
    "    print(train_sample.columns.tolist()[:50])\n",
    "except Exception as e:\n",
    "    print(\"Failed to read train sample:\", e)\n",
    "    train_sample = None\n",
    "\n",
    "try:\n",
    "    test_sample = pd.read_csv(DATATEST, nrows=sample_nrows)\n",
    "    print(\"Test sample loaded. Shape:\", test_sample.shape)\n",
    "    print(test_sample.columns.tolist()[:50])\n",
    "except Exception as e:\n",
    "    print(\"Failed to read test sample:\", e)\n",
    "    test_sample = None\n",
    "\n",
    "# Detect time columns (scheduled/actual)\n",
    "possible_time_columns = [c for c in (train_sample.columns if train_sample is not None else []) if \"DATE\" in c.upper() or \"DEPART\" in c.upper() or \"TIME\" in c.upper()]\n",
    "\n",
    "TIME_COLS = {\"scheduled\": None, \"actual\": None}\n",
    "for c in (train_sample.columns if train_sample is not None else []):\n",
    "    cu = c.upper()\n",
    "    if \"SCHEDULED\" in cu and TIME_COLS[\"scheduled\"] is None:\n",
    "        TIME_COLS[\"scheduled\"] = c\n",
    "    if \"ACTUAL\" in cu and TIME_COLS[\"actual\"] is None:\n",
    "        TIME_COLS[\"actual\"] = c\n",
    "\n",
    "if TIME_COLS[\"scheduled\"] is None:\n",
    "    for c in (train_sample.columns if train_sample is not None else []):\n",
    "        if \"DEPARTURE\" in c.upper() or \"SCHEDULE\" in c.upper():\n",
    "            TIME_COLS[\"scheduled\"] = c\n",
    "            break\n",
    "\n",
    "if TIME_COLS[\"actual\"] is None:\n",
    "    for c in (train_sample.columns if train_sample is not None else []):\n",
    "        if \"ACTUAL\" in c.upper() or \"ARRIVAL\" in c.upper():\n",
    "            TIME_COLS[\"actual\"] = c\n",
    "            break\n",
    "\n",
    "print(\"Detected time columns:\", TIME_COLS)\n",
    "\n",
    "parse_dates_cols = [col for col in TIME_COLS.values() if col]\n",
    "load_kwargs = {\"parse_dates\": parse_dates_cols} if parse_dates_cols else {}\n",
    "\n",
    "use_nrows = None\n",
    "if DOWNSAMPLE:\n",
    "    use_nrows = MAX_ROWS\n",
    "\n",
    "# Load full dataframes (memory-aware)\n",
    "try:\n",
    "    train_df = pd.read_csv(DATATRAIN, nrows=use_nrows, parse_dates=parse_dates_cols)\n",
    "    print(\"Train shape:\", train_df.shape)\n",
    "except MemoryError:\n",
    "    print('MemoryError during full read, falling back to DOWNSAMPLE using MAX_ROWS')\n",
    "    use_nrows = MAX_ROWS\n",
    "    train_df = pd.read_csv(DATATRAIN, nrows=use_nrows, parse_dates=parse_dates_cols)\n",
    "    print(\"Train shape (downsampled):\", train_df.shape)\n",
    "\n",
    "if os.path.exists(DATATEST):\n",
    "    try:\n",
    "        test_df = pd.read_csv(DATATEST, nrows=use_nrows, parse_dates=parse_dates_cols)\n",
    "        print(\"Test shape:\", test_df.shape)\n",
    "    except Exception as e:\n",
    "        print('Test load failed:', e)\n",
    "        test_df = None\n",
    "else:\n",
    "    test_df = None\n",
    "    print(\"Test path not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ca210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "\n",
    "## Section 3: Initial Data Inspection & Quick Cleaning\n",
    "\n",
    "# Basic info and sample head\n",
    "train_df.info()\n",
    "train_df.head()\n",
    "\n",
    "# ID column detection and cast to str\n",
    "id_cols = [c for c in train_df.columns if (\"ID\" in c.upper() or c.upper().endswith(\"_ID\"))]\n",
    "print(\"ID columns:\", id_cols)\n",
    "for c in id_cols:\n",
    "    train_df[c] = train_df[c].astype(str)\n",
    "\n",
    "# Ensure DELAY_MINUTES exists or compute\n",
    "if \"DELAY_MINUTES\" not in train_df.columns:\n",
    "    if TIME_COLS.get(\"scheduled\") and TIME_COLS.get(\"actual\"):\n",
    "        sched_col = TIME_COLS[\"scheduled\"]\n",
    "        act_col = TIME_COLS[\"actual\"]\n",
    "        print(f\"Attempting to compute DELAY_MINUTES from {sched_col} and {act_col}...\")\n",
    "\n",
    "        def robust_parse_datetime(series, base_date_col=None):\n",
    "            \"\"\"Parse a pandas Series into datetimes handling several common formats.\n",
    "               Returns a pandas Series of dtype datetime64[ns] with NaT where parsing failed.\n",
    "            \"\"\"\n",
    "            s = series.copy()\n",
    "\n",
    "            # Primary try: pandas parser\n",
    "            dt = pd.to_datetime(s, errors='coerce', infer_datetime_format=True)\n",
    "            success = dt.notna().mean()\n",
    "            if success > 0.7:\n",
    "                return dt\n",
    "\n",
    "            # Heuristic: numeric values that represent hour-of-day as float (e.g., 2.0 -> 02:00)\n",
    "            if pd.api.types.is_numeric_dtype(s):\n",
    "                mx = s.max(skipna=True)\n",
    "                if mx is not None and mx <= 24:\n",
    "                    # treat values as hour floats\n",
    "                    base_date = pd.Timestamp(\"1970-01-01\")\n",
    "                    dt2 = base_date + pd.to_timedelta(s.astype(float), unit='h')\n",
    "                    return dt2\n",
    "                if mx is not None and mx <= 2359:\n",
    "                    # treat as HHMM integer\n",
    "                    ints = s.fillna(0).astype(int).astype(str).str.zfill(4)\n",
    "                    dt2 = pd.to_datetime(ints, format='%H%M', errors='coerce')\n",
    "                    return dt2\n",
    "                # If very large -> epoch seconds or ms\n",
    "                if mx is not None and mx > 1e9:\n",
    "                    # choose ms if likely\n",
    "                    unit = 's'\n",
    "                    if mx > 1e12:\n",
    "                        unit = 'us'\n",
    "                    elif mx > 1e10:\n",
    "                        unit = 'ms'\n",
    "                    dt2 = pd.to_datetime(s, unit=unit, errors='coerce')\n",
    "                    return dt2\n",
    "\n",
    "            # If strings like '2.0', try interpret as hour float\n",
    "            s_str = s.astype(str).str.strip()\n",
    "            mask_hour = s_str.str.match(r'^\\d+\\.?\\d*$')\n",
    "            if mask_hour.any():\n",
    "                try:\n",
    "                    numeric = s_str[mask_hour].astype(float)\n",
    "                    base_date = pd.Timestamp(\"1970-01-01\")\n",
    "                    dt_temp = base_date + pd.to_timedelta(numeric, unit='h')\n",
    "                    result = pd.Series(pd.NaT, index=s.index, dtype='datetime64[ns]')\n",
    "                    result.loc[mask_hour] = dt_temp\n",
    "                    # Also try to fill other entries by parsing directly\n",
    "                    other_mask = ~mask_hour\n",
    "                    if other_mask.any():\n",
    "                        result.loc[other_mask] = pd.to_datetime(s_str[other_mask], errors='coerce', infer_datetime_format=True)\n",
    "                    return result\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            # Try replacing '.' with ':' (e.g., '02.30' -> '02:30')\n",
    "            s_colon = s_str.str.replace('.', ':', regex=False)\n",
    "            dt3 = pd.to_datetime(s_colon, errors='coerce', infer_datetime_format=True)\n",
    "            if dt3.notna().mean() > 0.3:\n",
    "                return dt3\n",
    "\n",
    "            # If we have a base_date_col available (like SCHEDULED_DT or DATE), combine date with time-of-day patterns\n",
    "            if base_date_col is not None and base_date_col in train_df.columns:\n",
    "                try:\n",
    "                    base_dates = pd.to_datetime(train_df[base_date_col], errors='coerce')\n",
    "                    # For numeric or short string times, try create HH:MM\n",
    "                    # handle floats hours\n",
    "                    if mask_hour.any():\n",
    "                        result = base_dates.copy().astype('datetime64[ns]')\n",
    "                        hours = s_str[mask_hour].astype(float)\n",
    "                        result.loc[mask_hour] = base_dates.loc[mask_hour] + pd.to_timedelta(hours, unit='h')\n",
    "                        return result\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            # fallback to try to coerce with infer format\n",
    "            return dt\n",
    "\n",
    "        sched_dt = robust_parse_datetime(train_df[sched_col], base_date_col='SCHEDULED_DT')\n",
    "        act_dt = robust_parse_datetime(train_df[act_col], base_date_col='SCHEDULED_DT')\n",
    "\n",
    "        parsed_info = {\n",
    "            'scheduled_parsed': float(sched_dt.notna().mean()),\n",
    "            'actual_parsed': float(act_dt.notna().mean())\n",
    "        }\n",
    "        print('Parsing success rates:', parsed_info)\n",
    "\n",
    "        # If both parsed reasonably well, compute delay\n",
    "        if (sched_dt.notna().mean() > 0.05) and (act_dt.notna().mean() > 0.05):\n",
    "            train_df['SCHEDULED_DT'] = sched_dt.where(sched_dt.notna(), train_df.get('SCHEDULED_DT'))\n",
    "            train_df['ACTUAL_DT'] = act_dt\n",
    "            train_df['DELAY_MINUTES'] = (train_df['ACTUAL_DT'] - train_df['SCHEDULED_DT']).dt.total_seconds() / 60\n",
    "            print('Computed DELAY_MINUTES; NaN count:', train_df['DELAY_MINUTES'].isnull().sum())\n",
    "        else:\n",
    "            print('Warning: Could not reliably parse scheduled/actual columns into datetimes.\\n  - scheduled parsed fraction:', parsed_info['scheduled_parsed'], '\\n  - actual parsed fraction:', parsed_info['actual_parsed'])\n",
    "            # As fallback, if a numeric 'DELAY_MINUTES' column exists in a different column name, try to find it\n",
    "            # e.g., 'DELAY' or 'DELAY_MIN' or 'DELAY_MINUTES'\n",
    "            possible_delay_cols = [c for c in train_df.columns if 'DELAY' in c.upper() and 'MIN' in c.upper()]\n",
    "            if possible_delay_cols:\n",
    "                print('Found possible delay columns:', possible_delay_cols)\n",
    "                # Use the first candidate\n",
    "                train_df['DELAY_MINUTES'] = train_df[possible_delay_cols[0]].astype(float)\n",
    "            else:\n",
    "                # set to NaN and warn\n",
    "                train_df['DELAY_MINUTES'] = np.nan\n",
    "                print('No fallback delay column found; DELAY_MINUTES set to NaN')\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"DELAY_MINUTES not present and time columns not detected.\")\n",
    "\n",
    "# Derive time features\n",
    "if TIME_COLS.get(\"scheduled\"):\n",
    "    # Ensure SCHEDULED_DT exists; try to parse if not\n",
    "    if 'SCHEDULED_DT' not in train_df.columns:\n",
    "        try:\n",
    "            train_df['SCHEDULED_DT'] = pd.to_datetime(train_df[TIME_COLS['scheduled']], errors='coerce', infer_datetime_format=True)\n",
    "        except Exception:\n",
    "            train_df['SCHEDULED_DT'] = pd.NaT\n",
    "\n",
    "    train_df[\"HOUR\"] = train_df[\"SCHEDULED_DT\"].dt.hour\n",
    "    train_df[\"DATE\"] = train_df[\"SCHEDULED_DT\"].dt.date\n",
    "    train_df[\"MONTH\"] = train_df[\"SCHEDULED_DT\"].dt.month\n",
    "    train_df[\"WEEKDAY\"] = train_df[\"SCHEDULED_DT\"].dt.weekday\n",
    "\n",
    "# Missingness summary\n",
    "missing_summary = train_df.isnull().mean().sort_values(ascending=False)\n",
    "print(missing_summary.head(30))\n",
    "\n",
    "# Drop duplicates\n",
    "before_dups = len(train_df)\n",
    "train_df.drop_duplicates(inplace=True)\n",
    "print(f\"Dropped {before_dups - len(train_df)} exact duplicates\")\n",
    "\n",
    "# Quick view of numeric columns\n",
    "numeric_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(\"Numeric columns sample:\", numeric_cols[:40])\n",
    "\n",
    "print('Preview:')\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37f6b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: show presence of demo variables and last RESULTS\n",
    "if 'RESULTS' not in globals():\n",
    "    RESULTS = []\n",
    "for name in ['rf_pipeline', 'rf_demo', 'pred_demo', 'y_val_demo', 'y_true_demo', 'results_df']:\n",
    "    print(name, 'in globals():', name in globals())\n",
    "\n",
    "print('\\nLast RESULTS item:')\n",
    "print(RESULTS[-1] if len(RESULTS) > 0 else 'No results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a695643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fallback to compute HOUR from scheduled column (if SCHEDULED_DT parsing failed)\n",
    "if TIME_COLS.get('scheduled') and ('HOUR' not in train_df.columns or train_df['HOUR'].isnull().all()):\n",
    "    sc = TIME_COLS['scheduled']\n",
    "    if sc in train_df.columns:\n",
    "        s = train_df[sc]\n",
    "        if pd.api.types.is_numeric_dtype(s):\n",
    "            # treat numeric less than 24 as hour\n",
    "            if s.max(skipna=True) <= 24:\n",
    "                train_df['HOUR'] = s.fillna(0).astype(float).apply(lambda x: int(np.floor(x)))\n",
    "        else:\n",
    "            # try to extract leading hour from string patterns\n",
    "            s_str = s.astype(str)\n",
    "            # match HH or HH:MM\n",
    "            import re\n",
    "            def extract_hour(ss):\n",
    "                if pd.isna(ss):\n",
    "                    return np.nan\n",
    "                m = re.match(r\"(\\d{1,2})[:\\.\\s-]?\", ss)\n",
    "                if m:\n",
    "                    try:\n",
    "                        return int(m.group(1))\n",
    "                    except:\n",
    "                        return np.nan\n",
    "                return np.nan\n",
    "            train_df['HOUR'] = s_str.apply(extract_hour)\n",
    "\n",
    "# Convert HOUR to integer or NaN\n",
    "train_df['HOUR'] = train_df['HOUR'].apply(lambda x: int(x) if not pd.isna(x) else np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55691f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "\n",
    "## Section 4: Target Handling & Missing Value Imputation\n",
    "\n",
    "# 4.1 Handle negative DELAY_MINUTES values\n",
    "NEGATIVE_TO_ZERO = True\n",
    "if NEGATIVE_TO_ZERO:\n",
    "    n_neg = (train_df['DELAY_MINUTES'] < 0).sum()\n",
    "    print(f\"Negative delays: {n_neg} rows. Setting them to 0.\")\n",
    "    train_df.loc[train_df['DELAY_MINUTES'] < 0, 'DELAY_MINUTES'] = 0\n",
    "\n",
    "# 4.2 Missing value imputation: numeric groupwise median and categorical constant\n",
    "# Numeric columns - do groupwise median imputation on station and hour for known fields\n",
    "numeric_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Identify numeric features to impute (exclude target and date columns)\n",
    "exclude_cols = ['DELAY_MINUTES'] + [\"SCHEDULED_DT\"]\n",
    "impute_numeric_cols = [c for c in numeric_cols if c not in exclude_cols]\n",
    "\n",
    "# Example groupby median for a subset\n",
    "for c in impute_numeric_cols:\n",
    "    if train_df[c].isnull().sum() > 0:\n",
    "        try:\n",
    "            gp_med = train_df.groupby([\"STATION_ID\", \"HOUR\"])[c].transform(\"median\")\n",
    "            train_df[c] = train_df[c].fillna(gp_med)\n",
    "            # fallback to global median\n",
    "            train_df[c] = train_df[c].fillna(train_df[c].median())\n",
    "        except Exception:\n",
    "            train_df[c] = train_df[c].fillna(train_df[c].median())\n",
    "\n",
    "# Fill categorical missing with 'Unknown'\n",
    "cat_cols = train_df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "for c in cat_cols:\n",
    "    train_df[c] = train_df[c].fillna('Unknown')\n",
    "\n",
    "# Confirm missing values\n",
    "print(train_df.isnull().sum().loc[lambda x: x>0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81bdd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "\n",
    "## Section 5: Outlier Detection & Winsorization\n",
    "\n",
    "# Compute quantiles\n",
    "q01 = train_df['DELAY_MINUTES'].quantile(0.01)\n",
    "q99 = train_df['DELAY_MINUTES'].quantile(0.99)\n",
    "mean_val = train_df['DELAY_MINUTES'].mean()\n",
    "print(f\"Delay quantiles: 1%={q01:.2f}, 99%={q99:.2f}, mean={mean_val:.2f}\")\n",
    "\n",
    "# Use explicit WINSOR_CAP defined in setup but fallback to q99 if smaller\n",
    "winsor_cap = min(q99, WINSOR_CAP) if 'WINSOR_CAP' in globals() else q99\n",
    "print(f\"Winsorization cap (using min(q99, WINSOR_CAP)): {winsor_cap}\")\n",
    "\n",
    "# ... rest of plotting code unchanged ...\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.histplot(train_df['DELAY_MINUTES'], bins=80, kde=False)\n",
    "plt.title('DELAY_MINUTES distribution')\n",
    "plt.xlabel('Minutes')\n",
    "plt.xlim(0, min(train_df['DELAY_MINUTES'].quantile(0.999), 500))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "sns.boxplot(x=train_df['DELAY_MINUTES'])\n",
    "plt.xlim(0, min(train_df['DELAY_MINUTES'].quantile(0.999), 500))\n",
    "plt.title('Boxplot of DELAY_MINUTES')\n",
    "plt.show()\n",
    "\n",
    "# Winsorization at the chosen cap\n",
    "train_df['DELAY_MINUTES_WINSORIZED'] = np.minimum(train_df['DELAY_MINUTES'], winsor_cap)\n",
    "rows_clipped = (train_df['DELAY_MINUTES'] > winsor_cap).sum()\n",
    "print(f\"Winsorization cap: {winsor_cap}. Rows clipped: {rows_clipped}\")\n",
    "\n",
    "# For further steps we'll use the winsorized target\n",
    "train_df['TARGET'] = train_df['DELAY_MINUTES_WINSORIZED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34418847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "\n",
    "## Section 6: Target Transformation (Log1p) & Inverse Transform\n",
    "\n",
    "train_df['TARGET_LOG1P'] = np.log1p(train_df['TARGET'])\n",
    "\n",
    "# Transform functions\n",
    "inv_log1p = lambda x: np.expm1(x)\n",
    "\n",
    "print('Original target skew:', train_df['TARGET'].skew())\n",
    "print('Transformed (log1p) target skew:', train_df['TARGET_LOG1P'].skew())\n",
    "\n",
    "# Plot distribution after transformation\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.histplot(train_df['TARGET'], bins=80)\n",
    "plt.title('Target (winsorized) distribution')\n",
    "plt.subplot(1,2,2)\n",
    "sns.histplot(train_df['TARGET_LOG1P'], bins=80)\n",
    "plt.title('Target log1p distribution')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72e69ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "\n",
    "## Section 7: EDA - Univariate & Multivariate\n",
    "\n",
    "# Basic descriptive statistics\n",
    "print('Target (winsorized) stats:')\n",
    "print(train_df['TARGET'].describe())\n",
    "\n",
    "# Show skewness/kurtosis\n",
    "from scipy.stats import skew, kurtosis\n",
    "print('Skew:', skew(train_df['TARGET']))\n",
    "print('Kurtosis:', kurtosis(train_df['TARGET']))\n",
    "\n",
    "# Average delay by HOUR\n",
    "hour_grp = train_df.groupby('HOUR')['TARGET'].mean().reset_index()\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.lineplot(x='HOUR', y='TARGET', data=hour_grp)\n",
    "plt.title('Average delay by hour of day')\n",
    "plt.show()\n",
    "\n",
    "# Average delay by month\n",
    "month_grp = train_df.groupby('MONTH')['TARGET'].mean().reset_index()\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.lineplot(x='MONTH', y='TARGET', data=month_grp)\n",
    "plt.title('Average delay by month')\n",
    "plt.show()\n",
    "\n",
    "# Top 10 busiest stations by count\n",
    "if 'STATION_ID' in train_df.columns:\n",
    "    busy_stations = train_df['STATION_ID'].value_counts().nlargest(10).index\n",
    "    plt.figure(figsize=(12,6))\n",
    "    sns.boxplot(x='STATION_ID', y='TARGET', data=train_df[train_df['STATION_ID'].isin(busy_stations)])\n",
    "    plt.title('Delay distribution for top 10 stations')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "# Correlation matrix among selected numeric columns\n",
    "num_cols_for_corr = ['TARGET'] + [c for c in numeric_cols if c not in ['DELAY_MINUTES','TARGET','TARGET_LOG1P']][:8]\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(train_df[num_cols_for_corr].corr(), annot=True, fmt='.2f')\n",
    "plt.title('Correlation matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5936ebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "\n",
    "## Section 8: Feature Engineering: Time, Lag, Rolling, Interactions\n",
    "\n",
    "# Time cyclical features\n",
    "train_df['HOUR_SIN'] = np.sin(2 * np.pi * train_df['HOUR'] / 24)\n",
    "train_df['HOUR_COS'] = np.cos(2 * np.pi * train_df['HOUR'] / 24)\n",
    "\n",
    "# Compute lag and rolling features using the helper functions (safe fallback if TRAIN_ID/STATION_ID missing)\n",
    "train_df = compute_prev_delay_safe(train_df)\n",
    "train_df = compute_rolling_features_safe(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecac493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "\n",
    "# Quick small test for compute_prev_delay and compute_rolling_features - sanity check\n",
    "import pandas as pd, numpy as np\n",
    "# with route column\n",
    "df_test = pd.DataFrame({ 'SCHEDULED_DT': pd.date_range('2020-01-01', periods=5, freq='D'), 'TARGET':[10,20,5,0,3], 'STATION_ID':['A','A','A','B','B'] })\n",
    "# without route column (simulate dataset with no TRAIN_ID/STATION_ID)\n",
    "df_test_no_route = df_test.drop(columns=['STATION_ID']).copy()\n",
    "print('route present:', _get_route_column(df_test))\n",
    "print('route missing:', _get_route_column(df_test_no_route))\n",
    "print('Compute prev delay with route:')\n",
    "print(compute_prev_delay(df_test))\n",
    "print('Compute prev delay without route:')\n",
    "print(compute_prev_delay(df_test_no_route))\n",
    "print('Compute rolling with route:')\n",
    "print(compute_rolling_features(df_test))\n",
    "print('Compute rolling without route:')\n",
    "print(compute_rolling_features(df_test_no_route))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7887d64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "\n",
    "## Section 9: Feature Encoding & Scaling with Pipelines\n",
    "\n",
    "# Select features automatically\n",
    "candidate_features = []\n",
    "\n",
    "# Numeric features\n",
    "numeric_features = ['DISTANCE', 'STOPS', 'PASSENGER_LOAD', 'PREV_DELAY', 'ROLLING_MEAN_DELAY_7D', 'WEATHER_IMPACT', 'HOUR_SIN', 'HOUR_COS']\n",
    "numeric_features = [f for f in numeric_features if f in train_df.columns]\n",
    "\n",
    "# Categorical features (IDs and operators)\n",
    "cat_features_all = id_cols + [c for c in ['OPERATOR_ID', 'ROUTE_ID', 'TRAIN_TYPE', 'STATION_NAME'] if c in train_df.columns]\n",
    "cat_features_all = [c for c in cat_features_all if c in train_df.columns]\n",
    "\n",
    "# Auto selection small cardinality for one-hot encoding\n",
    "onehot_features, label_features = [], []\n",
    "for c in cat_features_all:\n",
    "    nunique = train_df[c].nunique()\n",
    "    if nunique <= 50:\n",
    "        onehot_features.append(c)\n",
    "    else:\n",
    "        label_features.append(c)\n",
    "\n",
    "print('Numeric features:', numeric_features)\n",
    "print('OneHot features:', onehot_features)\n",
    "print('Label/High-card features:', label_features)\n",
    "\n",
    "# For label features we'll use simple ordinal encoding using scikit-learn's OrdinalEncoder or mapping.\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "if label_features:\n",
    "    # Fit mapping using fitted categories\n",
    "    oe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    train_df[label_features] = oe.fit_transform(train_df[label_features].fillna('Unknown'))\n",
    "\n",
    "# Build pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, onehot_features)\n",
    "    ],\n",
    "    remainder='passthrough'  # keep other features if needed\n",
    ")\n",
    "\n",
    "# Final small helper to assemble X and y\n",
    "FEATURES = numeric_features + onehot_features + label_features\n",
    "print('Final FEATURES list count:', len(FEATURES))\n",
    "\n",
    "X = train_df[FEATURES]\n",
    "y = train_df['TARGET_LOG1P']  # model on the log scale\n",
    "\n",
    "# A quick check of shape\n",
    "print('X shape:', X.shape, 'y shape:', y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6714b3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "\n",
    "## Section 10: Prepare Train/Validation Splits (Time Series)\n",
    "\n",
    "# Use a time cutoff: last n days as holdout\n",
    "holdout_days = 60\n",
    "max_date = train_df['SCHEDULED_DT'].max()\n",
    "train_cutoff = max_date - pd.Timedelta(days=holdout_days)\n",
    "\n",
    "train_idx = train_df['SCHEDULED_DT'] < train_cutoff\n",
    "val_idx = train_df['SCHEDULED_DT'] >= train_cutoff\n",
    "\n",
    "X_train = X.loc[train_idx]\n",
    "X_val = X.loc[val_idx]\n",
    "y_train = y.loc[train_idx]\n",
    "y_val = y.loc[val_idx]\n",
    "\n",
    "print('Train set:', X_train.shape, 'Validation set:', X_val.shape)\n",
    "\n",
    "# For cross-validation we'll build a TimeSeriesSplit object\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "print('TimeSeriesSplit created with 5 splits')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c5198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "\n",
    "## Section 11: Baseline Models (Mean & Linear Regression)\n",
    "\n",
    "# Baseline: predict mean of y_train (in log space)\n",
    "mean_train_log = y_train.mean()\n",
    "\n",
    "# Predictions (log space):\n",
    "baseline_pred_log = np.full(len(y_val), mean_train_log)\n",
    "baseline_pred = np.expm1(baseline_pred_log)\n",
    "\n",
    "y_val_original = np.expm1(y_val)\n",
    "\n",
    "metrics_baseline = metrics_summary(y_val_original, baseline_pred)\n",
    "metrics_baseline\n",
    "\n",
    "# Baseline 2: Linear Regression\n",
    "linear_pipe = Pipeline(steps=[('preproc', preprocessor), ('linear', LinearRegression())])\n",
    "linear_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Predict and inverse transform\n",
    "y_pred_log_lin = linear_pipe.predict(X_val)\n",
    "y_pred_lin = np.expm1(y_pred_log_lin)\n",
    "\n",
    "metrics_linear = metrics_summary(y_val_original, y_pred_lin)\n",
    "\n",
    "print('Baseline metrics (original scale):', metrics_baseline)\n",
    "print('Linear Regression metrics (original scale):', metrics_linear)\n",
    "\n",
    "RESULTS.append({'model':'Baseline Mean', **metrics_baseline})\n",
    "RESULTS.append({'model':'Linear Regression', **metrics_linear})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5773f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "\n",
    "## Section 12: Random Forest Regressor: Train & Evaluate\n",
    "\n",
    "rf_pipe = Pipeline(steps=[('preproc', preprocessor), ('rf', RandomForestRegressor(random_state=RANDOM_STATE, n_jobs=-1))])\n",
    "\n",
    "# Hyperparameter space\n",
    "rf_param_grid = {\n",
    "    'rf__n_estimators': [100, 200],\n",
    "    'rf__max_depth': [10, 20, None],\n",
    "    'rf__min_samples_leaf': [1, 3, 5],\n",
    "    'rf__max_features': ['auto', 'sqrt']\n",
    "}\n",
    "\n",
    "# Time-aware CV via TimeSeriesSplit\n",
    "tscv_rf = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "rf_search = RandomizedSearchCV(rf_pipe, rf_param_grid, n_iter=6, cv=tscv_rf, scoring='neg_root_mean_squared_error', n_jobs=-1, random_state=RANDOM_STATE, verbose=1)\n",
    "start=time.time()\n",
    "rf_search.fit(X_train, y_train)\n",
    "end=time.time()\n",
    "\n",
    "print('Best RF params:', rf_search.best_params_)\n",
    "print('Best RF CV score (neg RMSE in log space):', rf_search.best_score_)\n",
    "\n",
    "# Evaluate on validation set\n",
    "rf_best = rf_search.best_estimator_\n",
    "rf_pred_log = rf_best.predict(X_val)\n",
    "rf_pred = np.expm1(rf_pred_log)\n",
    "metrics_rf = metrics_summary(y_val_original, rf_pred)\n",
    "print('Random Forest metrics (original scale):', metrics_rf)\n",
    "\n",
    "RESULTS.append({'model':'Random Forest', **metrics_rf, 'tuning_time_s': end-start})\n",
    "\n",
    "# Feature importances (approx) - use numeric feature mapping\n",
    "try:\n",
    "    fi = rf_best.named_steps['rf'].feature_importances_\n",
    "    # Handle columns after preprocessing for the number of features\n",
    "    # We can compute feature names from preprocessor\n",
    "    # This is non-trivial with onehot; we provide the top numeric feature importance mapping approximately\n",
    "    print('RandomForest feature importances (sample):', fi[:10])\n",
    "except Exception as e:\n",
    "    print('Failed to extract RF feature importances:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6679ea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "\n",
    "## Section 13: XGBoost / LightGBM Champion Model with Hyperparameter Tuning\n",
    "\n",
    "if xgb is None and lgb is None:\n",
    "    print('Both XGBoost and LightGBM are not available. Skipping gradient boosting training.')\n",
    "else:\n",
    "    if xgb is not None:\n",
    "        print('Training XGBoost as the champion model (if available)')\n",
    "        xgb_pipe = Pipeline(steps=[('preproc', preprocessor), ('xgb', xgb.XGBRegressor(objective='reg:squarederror', random_state=RANDOM_STATE, n_jobs=-1, verbosity=1))])\n",
    "\n",
    "        xgb_param_grid = {\n",
    "            'xgb__n_estimators': [100, 300, 500],\n",
    "            'xgb__learning_rate': [0.01, 0.05, 0.1],\n",
    "            'xgb__max_depth': [4, 6, 8],\n",
    "            'xgb__reg_alpha': [0, 0.1, 1],\n",
    "            'xgb__reg_lambda': [1, 10],\n",
    "            'xgb__min_child_weight': [1, 5, 10],\n",
    "        }\n",
    "\n",
    "        search_iter = 12\n",
    "        xgb_search = RandomizedSearchCV(xgb_pipe, xgb_param_grid, n_iter=search_iter, cv=tscv, scoring='neg_root_mean_squared_error', n_jobs=-1, random_state=RANDOM_STATE, verbose=2)\n",
    "\n",
    "        start = time.time()\n",
    "        xgb_search.fit(X_train, y_train)\n",
    "        end = time.time()\n",
    "\n",
    "        print('Best XGB params', xgb_search.best_params_)\n",
    "        print('Best XGB CV score (neg RMSE log-scale):', xgb_search.best_score_)\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        xgb_best = xgb_search.best_estimator_\n",
    "        xgb_pred_log = xgb_best.predict(X_val)\n",
    "        xgb_pred = np.expm1(xgb_pred_log)\n",
    "        metrics_xgb = metrics_summary(y_val_original, xgb_pred)\n",
    "        print('XGBoost metrics (original scale):', metrics_xgb)\n",
    "\n",
    "        RESULTS.append({'model':'XGBoost (tuned)', **metrics_xgb, 'tuning_time_s': end-start})\n",
    "    else:\n",
    "        # If XGBoost not available, use LightGBM if present\n",
    "        if lgb is not None:\n",
    "            print('XGBoost not found, using LightGBM (as fallback).')\n",
    "            lgb_pipe = Pipeline(steps=[('preproc', preprocessor), ('lgb', lgb.LGBMRegressor(random_state=RANDOM_STATE, n_jobs=-1))])\n",
    "\n",
    "            lgb_param_grid = {\n",
    "                'lgb__n_estimators': [100, 300, 500],\n",
    "                'lgb__learning_rate': [0.01, 0.05, 0.1],\n",
    "                'lgb__max_depth': [-1, 10, 20],\n",
    "                'lgb__num_leaves': [31, 50, 100],\n",
    "                'lgb__min_child_samples': [5, 20],\n",
    "            }\n",
    "\n",
    "            lgb_search = RandomizedSearchCV(lgb_pipe, lgb_param_grid, n_iter=12, cv=tscv, scoring='neg_root_mean_squared_error', n_jobs=-1, random_state=RANDOM_STATE, verbose=2)\n",
    "            start = time.time()\n",
    "            lgb_search.fit(X_train, y_train)\n",
    "            end = time.time()\n",
    "\n",
    "            print('Best LGB params', lgb_search.best_params_)\n",
    "            print('Best LGB CV score (neg RMSE log-scale):', lgb_search.best_score_)\n",
    "\n",
    "            lgb_best = lgb_search.best_estimator_\n",
    "            lgb_pred_log = lgb_best.predict(X_val)\n",
    "            lgb_pred = np.expm1(lgb_pred_log)\n",
    "            metrics_lgb = metrics_summary(y_val_original, lgb_pred)\n",
    "            print('LightGBM metrics (original scale):', metrics_lgb)\n",
    "            RESULTS.append({'model':'LightGBM (tuned)', **metrics_lgb, 'tuning_time_s': end-start})\n",
    "        else:\n",
    "            print('No gradient boosting model available (xgboost/lightgbm)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52fbf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "\n",
    "## Section 14: Model Comparison Table & Evaluation Metrics\n",
    "\n",
    "results_df = pd.DataFrame(RESULTS)\n",
    "# round metrics for clarity\n",
    "for m in ['rmse','mae','r2']:\n",
    "    for col in results_df.columns:\n",
    "        if col.endswith(m):\n",
    "            results_df[col] = results_df[col].round(3)\n",
    "\n",
    "results_df\n",
    "\n",
    "# Plot comparison of RMSE\n",
    "plt.figure(figsize=(8,4))\n",
    "if 'rmse' in results_df.columns:\n",
    "    sns.barplot(data=results_df, x='model', y='rmse')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title('RMSE (lower is better) comparison')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d49a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "\n",
    "## Section 14b: Model Comparison Summary & Recommendation\n",
    "\n",
    "# Ensure results_df exists (it is created earlier from RESULTS)\n",
    "try:\n",
    "    if 'results_df' not in globals():\n",
    "        results_df = pd.DataFrame(RESULTS)\n",
    "\n",
    "    # If RMSE columns are on log or original scale, use 'rmse' (original scale) shown in the table\n",
    "    if 'rmse' not in results_df.columns and 'rmse' in [c.lower() for c in results_df.columns]:\n",
    "        # already normalized\n",
    "        pass\n",
    "\n",
    "    if 'rmse' in results_df.columns:\n",
    "        best_row = results_df.loc[results_df['rmse'].idxmin()]\n",
    "        print('Best model by RMSE:', best_row['model'], 'RMSE:', best_row['rmse'])\n",
    "        print('\\nFull Results:')\n",
    "        display(results_df.sort_values('rmse'))\n",
    "    else:\n",
    "        print('Results dataframe does not include RMSE column; printing RESULTS instead')\n",
    "        print(RESULTS)\n",
    "\n",
    "    # Recommendation message based on best\n",
    "def recommend_model(results_df):\n",
    "    if 'rmse' in results_df.columns:\n",
    "        best_idx = results_df['rmse'].idxmin()\n",
    "        best = results_df.loc[best_idx]\n",
    "        return f\"Recommended model: {best['model']} with RMSE={best['rmse']:.3f}. Consider LightGBM or XGBoost, tuned with Optuna if available.\"\n",
    "    return 'No recommendation (no RMSE available)'\n",
    "\n",
    "print(recommend_model(results_df))\n",
    "\n",
    "# Add a follow-up suggestion to test ensemble or stacking if single model performance saturates\n",
    "print('\\nSuggestion: If Best model is similar to others, try a lightweight stacking ensemble (avg/stack) or additional features: lag windows, weather, special event flags.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672a51cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "\n",
    "## Section 15b: Top Features & Worst Predictions Summary\n",
    "\n",
    "# Build a utility to extract feature names from preprocessor (sklearn>=1.0) safely\n",
    "\n",
    "def get_feature_names(preprocessor, numeric_features, onehot_features, label_features):\n",
    "    try:\n",
    "        # ColumnTransformer with get_feature_names_out (sklearn >=1.0)\n",
    "        names = preprocessor.get_feature_names_out()\n",
    "        return list(names)\n",
    "    except Exception:\n",
    "        # fallback: reconstruct approximate feature names\n",
    "        feat_names = []\n",
    "        feat_names.extend(numeric_features)\n",
    "        # For onehot, try access fitted categories\n",
    "        try:\n",
    "            if onehot_features and hasattr(preprocessor.named_transformers_['cat'].named_steps['onehot'], 'categories_'):\n",
    "                ohe = preprocessor.named_transformers_['cat'].named_steps['onehot']\n",
    "                for i, col in enumerate(onehot_features):\n",
    "                    cats = ohe.categories_[i]\n",
    "                    names_cat = [f\"{col}_{c}\" for c in cats]\n",
    "                    feat_names.extend(names_cat)\n",
    "        except Exception:\n",
    "            feat_names.extend(onehot_features)\n",
    "        feat_names.extend(label_features)\n",
    "        return feat_names\n",
    "\n",
    "# Find a pipeline to extract feature importances: prefer trained best models, else fall back to demo or rf pipeline\n",
    "best_est = None\n",
    "for varname in ['xgb_best', 'lgb_best', 'rf_best', 'xgb_opt_pipe', 'xgb_opt', 'rf_pipeline', 'rf_demo']:\n",
    "    if varname in globals():\n",
    "        best_est = globals()[varname]\n",
    "        print('Using model variable:', varname)\n",
    "        break\n",
    "\n",
    "if best_est is not None:\n",
    "    try:\n",
    "        # extract core model\n",
    "        core_model = None\n",
    "        if hasattr(best_est, 'named_steps'):\n",
    "            core_model = next((v for k, v in best_est.named_steps.items() if hasattr(v, 'feature_importances_')), None)\n",
    "        else:\n",
    "            core_model = best_est\n",
    "\n",
    "        if core_model is not None and hasattr(core_model, 'feature_importances_'):\n",
    "            fi = core_model.feature_importances_\n",
    "            feat_names = get_feature_names(preprocessor, numeric_features, onehot_features, label_features)\n",
    "            if len(feat_names) != len(fi):\n",
    "                # fallback: map to numeric features only\n",
    "                feat_names = [f for f in (numeric_features + onehot_features + label_features)][:len(fi)]\n",
    "            importances = pd.Series(fi, index=feat_names)\n",
    "            top10 = importances.sort_values(ascending=False).head(10)\n",
    "            print('\\nTop 10 features by importance:')\n",
    "            display(top10)\n",
    "        else:\n",
    "            print('Feature importances not found for core model; attempting permutation importance fallback')\n",
    "            from sklearn.inspection import permutation_importance\n",
    "            # Use a small sample to speed up\n",
    "            if 'X_train' in globals() and len(X_train) > 0:\n",
    "                sample = X_train.sample(min(200, len(X_train)), random_state=RANDOM_STATE)\n",
    "                y_sample = y_train.loc[sample.index] if 'y_train' in globals() else None\n",
    "                r = permutation_importance(best_est, sample, y_sample, scoring='neg_root_mean_squared_error', n_repeats=5, random_state=RANDOM_STATE, n_jobs=1)\n",
    "                perm_importances = pd.Series(r.importances_mean, index=(get_feature_names(preprocessor, numeric_features, onehot_features, label_features)[:len(r.importances_mean)]))\n",
    "                top10 = perm_importances.sort_values(ascending=False).head(10)\n",
    "                print('\\nTop 10 features by permutation importance:')\n",
    "                display(top10)\n",
    "            else:\n",
    "                print('No X_train/y_train found; cannot compute permutation importance')\n",
    "    except Exception as e:\n",
    "        print('Failed to compute feature importances:', e)\n",
    "else:\n",
    "    print('No trained model variable found in globals to compute feature importance.')\n",
    "\n",
    "# Worst predictions summary\n",
    "# Try to use 'top50' variable if present; else compute using available val set and a model\n",
    "try:\n",
    "    if 'top50' in globals():\n",
    "        print('\\nTop 10 worst predictions (subset of top50):')\n",
    "        display(top50.head(10)[['TRAIN_ID' if 'TRAIN_ID' in top50.columns else id_cols[0], 'SCHEDULED_DT', 'y_true', 'y_pred', 'abs_error']])\n",
    "    elif 'val_demo' in globals() and 'pred_demo' in globals():\n",
    "        val_df_demo = val_demo.copy()\n",
    "        val_df_demo['y_true'] = y_true_demo\n",
    "        val_df_demo['y_pred'] = pred_demo\n",
    "        val_df_demo['abs_error'] = (val_df_demo['y_true'] - val_df_demo['y_pred']).abs()\n",
    "        top10demo = val_df_demo.nlargest(10, 'abs_error')\n",
    "        print('\\nTop 10 worst predictions (demo):')\n",
    "        display(top10demo[[c for c in ['TRAIN_NUMBER', 'COACH_ID', 'SCHEDULED_DT', 'y_true', 'y_pred', 'abs_error'] if c in top10demo.columns]])\n",
    "    else:\n",
    "        print('\\nNo worst predictions available yet in globals')\n",
    "except Exception as e:\n",
    "    print('Failed to display worst predictions:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2905454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "\n",
    "## Section 15b: Top Features & Worst Predictions Summary\n",
    "\n",
    "# Build a utility to extract feature names from preprocessor (sklearn>=1.0) safely\n",
    "\n",
    "def get_feature_names(preprocessor, numeric_features, onehot_features, label_features):\n",
    "    try:\n",
    "        # ColumnTransformer with get_feature_names_out\n",
    "        names = preprocessor.get_feature_names_out()\n",
    "        return list(names)\n",
    "    except Exception:\n",
    "        # fallback: reconstruct approximate feature names\n",
    "        feat_names = []\n",
    "        feat_names.extend(numeric_features)\n",
    "        # For onehot, try access fitted categories\n",
    "        try:\n",
    "            if onehot_features and hasattr(preprocessor.named_transformers_['cat'].named_steps['onehot'], 'categories_'):\n",
    "                ohe = preprocessor.named_transformers_['cat'].named_steps['onehot']\n",
    "                for i, col in enumerate(onehot_features):\n",
    "                    cats = ohe.categories_[i]\n",
    "                    names_cat = [f\"{col}_{c}\" for c in cats]\n",
    "                    feat_names.extend(names_cat)\n",
    "        except Exception:\n",
    "            feat_names.extend(onehot_features)\n",
    "        feat_names.extend(label_features)\n",
    "        return feat_names\n",
    "\n",
    "# Determine best model and feature importances\n",
    "best_est = None\n",
    "if 'xgb_best' in globals():\n",
    "    best_est = xgb_best\n",
    "elif 'lgb_best' in globals():\n",
    "    best_est = lgb_best\n",
    "elif 'rf_best' in globals():\n",
    "    best_est = rf_best\n",
    "\n",
    "if best_est is not None:\n",
    "    print('Best model found for feature importance extraction:', best_est)\n",
    "    try:\n",
    "        # get core model and importances\n",
    "        core_model = None\n",
    "        if hasattr(best_est, 'named_steps'):\n",
    "            core_model = next((v for k, v in best_est.named_steps.items() if hasattr(v, 'feature_importances_')), None)\n",
    "        else:\n",
    "            core_model = best_est\n",
    "\n",
    "        if core_model is not None and hasattr(core_model, 'feature_importances_'):\n",
    "            fi = core_model.feature_importances_\n",
    "            feat_names = get_feature_names(preprocessor, numeric_features, onehot_features, label_features)\n",
    "            if len(feat_names) != len(fi):\n",
    "                # fallback to numeric features only\n",
    "                feat_names = numeric_features + onehot_features + label_features\n",
    "            importances = pd.Series(fi, index=feat_names)\n",
    "            top10 = importances.sort_values(ascending=False).head(10)\n",
    "            print('\\nTop 10 features by importance:')\n",
    "            display(top10)\n",
    "        else:\n",
    "            print('Feature importances not found for core model; attempting permutation importance as fallback')\n",
    "            from sklearn.inspection import permutation_importance\n",
    "            # Use a small sample due to time\n",
    "            sample = X_train.sample(min(200, len(X_train)), random_state=RANDOM_STATE)\n",
    "            y_sample = y_train.loc[sample.index]\n",
    "            r = permutation_importance(best_est, sample, y_sample, scoring='neg_root_mean_squared_error', n_repeats=10, random_state=RANDOM_STATE, n_jobs=1)\n",
    "            perm_importances = pd.Series(r.importances_mean, index=get_feature_names(preprocessor, numeric_features, onehot_features, label_features)[:len(r.importances_mean)])\n",
    "            top10 = perm_importances.sort_values(ascending=False).head(10)\n",
    "            print('\\nTop 10 features by permutation importance:')\n",
    "            display(top10)\n",
    "    except Exception as e:\n",
    "        print('Failed to compute feature importances:', e)\n",
    "else:\n",
    "    print('No best model found in notebook variables (xgb_best/lgb_best/rf_best). Skipping feature importance.')\n",
    "\n",
    "# Worst predictions summary already computed earlier as 'top50' in Section 15; show top 10\n",
    "try:\n",
    "    if 'top50' in globals():\n",
    "        print('\\nTop 10 worst predictions (subset of top50):')\n",
    "        display(top50.head(10)[['TRAIN_ID' if 'TRAIN_ID' in top50.columns else id_cols[0], 'SCHEDULED_DT', 'y_true', 'y_pred', 'abs_error']])\n",
    "    else:\n",
    "        print('top50 not found — run validation/prediction first to populate worst predictions.')\n",
    "except Exception as e:\n",
    "    print('Failed to display worst predictions:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de38a2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "\n",
    "## Section 16: Save Trained Model & Inference on DATATEST\n",
    "\n",
    "# Save preprocessor and model (safe guard to ensure best_model exists).\n",
    "if 'best_model' in globals() and best_model is not None:\n",
    "    best_model_name = 'xgboost_tuned' if 'xgb_best' in globals() else ('rf' if 'rf_best' in globals() else 'linear')\n",
    "    model_path = os.path.join(MODEL_DIR, f\"{best_model_name}_model.joblib\")\n",
    "    try:\n",
    "        joblib.dump(best_model, model_path)\n",
    "        print('Saved model to', model_path)\n",
    "    except Exception as e:\n",
    "        print('Failed to save best_model here:', e)\n",
    "else:\n",
    "    print('No best_model is defined yet; the later pipeline-saving cell will set and save the chosen model.')\n",
    "\n",
    "# Inference helper\n",
    "def predict_on_test(test_path):\n",
    "    print('Loading test data...')\n",
    "    test_df_local = pd.read_csv(test_path, parse_dates=parse_dates_cols)\n",
    "    # Add derived features used in training\n",
    "    if TIME_COLS.get('scheduled') in test_df_local.columns:\n",
    "        test_df_local['SCHEDULED_DT'] = pd.to_datetime(test_df_local[TIME_COLS['scheduled']])\n",
    "        test_df_local['HOUR'] = test_df_local['SCHEDULED_DT'].dt.hour\n",
    "        test_df_local['HOUR_SIN'] = np.sin(2 * np.pi * test_df_local['HOUR']/24)\n",
    "        test_df_local['HOUR_COS'] = np.cos(2 * np.pi * test_df_local['HOUR']/24)\n",
    "\n",
    "    # Preprocess label features mapping if used\n",
    "    if label_features:\n",
    "        try:\n",
    "            test_df_local[label_features] = oe.transform(test_df_local[label_features].fillna('Unknown'))\n",
    "        except Exception:\n",
    "            test_df_local[label_features] = test_df_local[label_features].fillna(-1)\n",
    "\n",
    "    # PREV_DELAY is not directly available for unseen trips; we set default\n",
    "    test_df_local['PREV_DELAY'] = test_df_local.get('PREV_DELAY', -1)\n",
    "    test_df_local['ROLLING_MEAN_DELAY_7D'] = test_df_local.get('ROLLING_MEAN_DELAY_7D', train_df['TARGET'].median())\n",
    "    test_df_local['WEATHER_IMPACT'] = test_df_local.get('WEATHER_IMPACT', 0.0)\n",
    "\n",
    "    # Extract features\n",
    "    X_test_local = test_df_local[FEATURES]\n",
    "\n",
    "    # Predict (model returns in log domain), inverse transform\n",
    "    pred_log_test = best_model.predict(X_test_local)\n",
    "    pred_test = np.expm1(pred_log_test)\n",
    "\n",
    "    # Save predictions\n",
    "    out = test_df_local[[TIME_COLS['scheduled']] if TIME_COLS['scheduled'] in test_df_local.columns else ['SCHEDULED_DT']].copy()\n",
    "    out['PRED_DELAY_MINUTES'] = pred_test\n",
    "    out['PRED_DELAY_MINUTES_LOG'] = pred_log_test\n",
    "    out.to_csv(os.path.join(MODEL_DIR, 'test_predictions.csv'), index=False)\n",
    "    print('Saved predictions to', os.path.join(MODEL_DIR, 'test_predictions.csv'))\n",
    "\n",
    "# Optionally run on DATATEST\n",
    "if os.path.exists(DATATEST):\n",
    "    predict_on_test(DATATEST)\n",
    "else:\n",
    "    print('DATATEST not found; skipping inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a26acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "\n",
    "## Section 17: Utilities: Logging, Versioning and Reproducibility\n",
    "\n",
    "# Log package versions\n",
    "import platform\n",
    "\n",
    "package_versions = {\n",
    "    'python_version': platform.python_version(),\n",
    "    'pandas': pd.__version__,\n",
    "    'numpy': np.__version__,\n",
    "    'sklearn': pkg_resources.get_distribution('scikit-learn').version,\n",
    "}\n",
    "print(package_versions)\n",
    "\n",
    "# Save a small experiment info file\n",
    "exp_info = {\n",
    "    'date': datetime.now().isoformat(),\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'winsor_cap': float(winsor_cap),\n",
    "    'dowsample': DOWNSAMPLE,\n",
    "    'best_model': best_model_name,\n",
    "}\n",
    "import json\n",
    "with open(os.path.join(MODEL_DIR, 'experiment_info.json'), 'w') as f:\n",
    "    json.dump(exp_info, f, indent=2)\n",
    "\n",
    "print('Saved experiment_info.json in', MODEL_DIR)\n",
    "\n",
    "\n",
    "# Final suggestions:\n",
    "# - Run hyperparameter tuning for longer and with Optuna for better model performance\n",
    "# - Add feature importance & SHAP analysis for interpretability\n",
    "# - Optionally use GPU and distributed training for scale\n",
    "\n",
    "print('Notebook complete. Next steps: cross-check columns, run full tuning, analyze worst cases and create monitoring/alerting.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88af688b",
   "metadata": {},
   "source": [
    "## Optional Enhancements (Optuna & SHAP)\n",
    "\n",
    "Below are optional steps to improve model quality and interpretability:\n",
    "1. Optuna hyperparameter tuning (XGBoost/LightGBM).  \n",
    "2. SHAP summary and dependence plots for the final model.  \n",
    "3. Store metrics and parameters in `models/` for experiment tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030a346e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# Optional: Optuna-based hyperparameter tuning for XGBoost (faster and more flexible than RandomizedSearch)\n",
    "\n",
    "# We installed optuna and xgboost earlier via the setup helper; check availability\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "if optuna is not None and xgb is not None and 'X_train' in globals() and 'y_train' in globals():\n",
    "    print('Running Optuna tuning for XGBoost (optional). This may take a while and uses TimeSeriesSplit CV.')\n",
    "\n",
    "    def optuna_optimize_xgb(trial):\n",
    "        param = {\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'rmse',\n",
    "            'booster': 'gbtree',\n",
    "            'tree_method': 'gpu_hist' if gpu_available() else 'hist',\n",
    "            'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "            'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 10.0),\n",
    "            'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 10.0),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 20),\n",
    "            'n_estimators': int(trial.suggest_categorical('n_estimators', [100,200,300,500])),\n",
    "            'random_state': RANDOM_STATE,\n",
    "        }\n",
    "\n",
    "        xgb_local = xgb.XGBRegressor(**param, verbosity=0, n_jobs=-1)\n",
    "        pipe_local = Pipeline(steps=[('preproc', preprocessor), ('xgb', xgb_local)])\n",
    "        try:\n",
    "            scores = cross_val_score(pipe_local, X_train, y_train, scoring='neg_root_mean_squared_error', cv=tscv, n_jobs=1)\n",
    "            return -1.0 * scores.mean()\n",
    "        except Exception as e:\n",
    "            print('Optuna trial failed on CV:', e)\n",
    "            return float('inf')\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(optuna_optimize_xgb, n_trials=20, show_progress_bar=True)\n",
    "\n",
    "    print('Optuna best value (RMSE):', study.best_value)\n",
    "    print('Optuna best params:', study.best_params)\n",
    "\n",
    "    # Fit best estimator on the full training set and evaluate\n",
    "    best_params = study.best_params\n",
    "    if 'n_estimators' in best_params:\n",
    "        best_params['n_estimators'] = int(best_params['n_estimators'])\n",
    "    best_params['random_state'] = RANDOM_STATE\n",
    "    best_params['tree_method'] = 'gpu_hist' if gpu_available() else 'hist'\n",
    "    xgb_opt = xgb.XGBRegressor(**best_params, verbosity=1, n_jobs=-1)\n",
    "\n",
    "    xgb_opt_pipe = Pipeline(steps=[('preproc', preprocessor), ('xgb', xgb_opt)])\n",
    "    xgb_opt_pipe.fit(X_train, y_train)\n",
    "\n",
    "    pred_log_opt = xgb_opt_pipe.predict(X_val)\n",
    "    pred_opt = np.expm1(pred_log_opt)\n",
    "    metrics_opt = metrics_summary(y_val_original, pred_opt)\n",
    "    print('Optuna XGBoost metrics:', metrics_opt)\n",
    "    RESULTS.append({'model': 'XGBoost (Optuna)', **metrics_opt})\n",
    "else:\n",
    "    print('Optuna or XGBoost not available (skipping Optuna tuning).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243c3145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# Optional: SHAP explainability for the final/best model\n",
    "\n",
    "try:\n",
    "    import shap\n",
    "except Exception:\n",
    "    import sys\n",
    "    try:\n",
    "        !{sys.executable} -m pip install shap\n",
    "        import shap\n",
    "    except Exception:\n",
    "        shap = None\n",
    "        print('SHAP not installed; skipping SHAP analysis.')\n",
    "\n",
    "# Choose the explainer model: prefer the optuna-fitted one, then the best pipelined model found earlier\n",
    "explainer_model = None\n",
    "if 'xgb_opt_pipe' in globals():\n",
    "    explainer_model = xgb_opt_pipe\n",
    "elif 'xgb_best' in globals():\n",
    "    explainer_model = xgb_best\n",
    "elif 'rf_best' in globals():\n",
    "    explainer_model = rf_best\n",
    "else:\n",
    "    explainer_model = linear_pipe\n",
    "\n",
    "if shap is not None and explainer_model is not None and 'X_train' in globals():\n",
    "    try:\n",
    "        sample_size = min(500, X_train.shape[0])\n",
    "        X_shap = X_train.sample(sample_size, random_state=RANDOM_STATE)\n",
    "\n",
    "        # If pipeline has preprocessor, transform the sample X\n",
    "        if hasattr(explainer_model, 'named_steps') and 'preproc' in explainer_model.named_steps:\n",
    "            X_shap_trans = explainer_model.named_steps['preproc'].transform(X_shap)\n",
    "        else:\n",
    "            X_shap_trans = X_shap.values\n",
    "\n",
    "        # get core model\n",
    "        if hasattr(explainer_model, 'named_steps') and ('xgb' in explainer_model.named_steps or 'rf' in explainer_model.named_steps):\n",
    "            core_model = explainer_model.named_steps.get('xgb') or explainer_model.named_steps.get('rf')\n",
    "            explainer = shap.TreeExplainer(core_model)\n",
    "        else:\n",
    "            # fallback to an explanation method less suited for linear/other models\n",
    "            core_model = explainer_model.named_steps.get('linear') if hasattr(explainer_model, 'named_steps') else explainer_model\n",
    "            explainer = shap.KernelExplainer(core_model.predict, X_shap_trans[:50])\n",
    "\n",
    "        shap_values = explainer.shap_values(X_shap_trans)\n",
    "\n",
    "        # Summary plot\n",
    "        plt.figure(figsize=(10,6))\n",
    "        shap.summary_plot(shap_values, X_shap_trans, show=False)\n",
    "        shap_summary_path = os.path.join(MODEL_DIR, 'shap_summary.png')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(shap_summary_path, dpi=150)\n",
    "        plt.close()\n",
    "        print('Saved SHAP summary to', shap_summary_path)\n",
    "\n",
    "        # Save an interactive HTML force plot for the first sample\n",
    "        try:\n",
    "            shap_html = os.path.join(MODEL_DIR, 'shap_force_plot.html')\n",
    "            shap.initjs()\n",
    "            # create a force plot for the mean of the sample\n",
    "            f = shap.force_plot(explainer.expected_value, shap_values[0,:], X_shap_trans[0,:], matplotlib=False)\n",
    "            shap.save_html(shap_html, f)\n",
    "            print('Saved SHAP force plot to', shap_html)\n",
    "        except Exception as e:\n",
    "            print('Could not produce interactive SHAP save:', e)\n",
    "\n",
    "    except Exception as e:\n",
    "        print('SHAP analysis failed:', e)\n",
    "else:\n",
    "    print('SHAP analysis skipped (shap not installed or no model/data available)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad43afa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# Save results/metrics to CSV for experiment tracking and model params\n",
    "\n",
    "if len(RESULTS) > 0:\n",
    "    try:\n",
    "        metrics_out = pd.DataFrame(RESULTS)\n",
    "        metrics_out_file = os.path.join(MODEL_DIR, 'metrics_summary.csv')\n",
    "        metrics_out.to_csv(metrics_out_file, index=False)\n",
    "        print('Saved metrics summary to', metrics_out_file)\n",
    "    except Exception as e:\n",
    "        print('Failed to save metrics summary:', e)\n",
    "\n",
    "# Append experiment info and metrics to a log file with timestamp\n",
    "try:\n",
    "    import datetime, json\n",
    "    exp_log = os.path.join(MODEL_DIR, 'metrics_log.csv')\n",
    "    exp_entry = globals().get('exp_info', {})\n",
    "    exp_entry.update({'metrics': RESULTS})\n",
    "\n",
    "    if not os.path.exists(exp_log):\n",
    "        with open(exp_log, 'w', newline='') as f:\n",
    "            f.write('timestamp,entry\\n')\n",
    "    with open(exp_log, 'a', newline='') as f:\n",
    "        f.write(datetime.datetime.now().isoformat() + ',' + json.dumps(exp_entry).replace('\\n', '') + '\\n')\n",
    "    print('Appended experiment entry to', exp_log)\n",
    "except Exception as e:\n",
    "    print('Failed to append experiment log:', e)\n",
    "\n",
    "# Save model params if a best model exists\n",
    "try:\n",
    "    model_params_file = os.path.join(MODEL_DIR, 'model_params.json')\n",
    "    if 'best_model' in globals() and hasattr(best_model, 'get_params'):\n",
    "        params = best_model.get_params()\n",
    "    elif 'xgb_opt_pipe' in globals():\n",
    "        # prefer optuna result\n",
    "        params = xgb_opt_pipe.named_steps['xgb'].get_params()\n",
    "    elif 'xgb_best' in globals():\n",
    "        params = xgb_best.named_steps['xgb'].get_params()\n",
    "    elif 'rf_best' in globals():\n",
    "        params = rf_best.named_steps['rf'].get_params()\n",
    "    else:\n",
    "        params = {'model': 'none'}\n",
    "\n",
    "    with open(model_params_file, 'w') as f:\n",
    "        json.dump(params, f, indent=2)\n",
    "    print('Saved model params JSON to', model_params_file)\n",
    "except Exception as e:\n",
    "    print('Could not log model params:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf6cf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check: print results summary (if created by demo)\n",
    "try:\n",
    "    if 'results_df' in globals():\n",
    "        print('results_df (head):')\n",
    "        display(results_df.head())\n",
    "    else:\n",
    "        print('RESULTS list:')\n",
    "        display(pd.DataFrame(RESULTS))\n",
    "except Exception as e:\n",
    "    print('Could not display results:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e05dd61",
   "metadata": {},
   "source": [
    "## Feature Dictionary\n",
    "\n",
    "- `TRAIN_ID`: Unique identifier for a train (string)\n",
    "- `STATION_ID`: Station identifier (string)\n",
    "- `SCHEDULED_DT`: Scheduled datetime for departure/arrival (datetime)\n",
    "- `ACTUAL_DT`: Actual datetime for departure/arrival (datetime)\n",
    "- `DELAY_MINUTES`: Observed delay in minutes (float)\n",
    "- `TARGET`: Winsorized target used for modelling (float)\n",
    "- `TARGET_LOG1P`: Log1p transformed TARGET for training\n",
    "- `PREV_DELAY`: Previous recorded delay on the same train or route (float)\n",
    "- `ROLLING_MEAN_DELAY_7D`, `ROLLING_MEAN_DELAY_30D`: Rolling mean delay values over 7/30 days\n",
    "- `HOUR`: hour of day (int)\n",
    "- `HOUR_SIN`, `HOUR_COS`: Cyclical encodings of hour (float)\n",
    "- `DISTANCE`, `STOPS`: Numeric operational features\n",
    "- `WEATHER_IMPACT`: Numeric or categorical proxy for weather contribution\n",
    "- `OPERATOR_ID`, `ROUTE_ID`: Categorical features describing route or operator\n",
    "\n",
    "> Tip: Keep this feature dictionary up-to-date when adding or removing engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0355a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# Finalize best_model variable and save the full pipeline (preprocessor + model)\n",
    "# This cell attempts to choose the best model variable available from earlier steps, then saves it to disk.\n",
    "best_model = None\n",
    "best_choice = None\n",
    "for var in ['xgb_opt_pipe','xgb_opt','xgb_best','lgb_best','rf_best','rf_search','rf_pipe','linear_pipe']:\n",
    "    if var in globals():\n",
    "        m = globals()[var]\n",
    "        if m is not None:\n",
    "            best_model = m\n",
    "            best_choice = var\n",
    "            break\n",
    "\n",
    "if best_model is None:\n",
    "    print('No trained model found in globals(). Using linear_pipe if available.')\n",
    "    best_model = globals().get('linear_pipe', None)\n",
    "    best_choice = 'linear_pipe' if best_model is not None else None\n",
    "\n",
    "print('Selected best_model:', best_choice)\n",
    "\n",
    "# Save pipeline as joblib if a model was found\n",
    "if best_model is not None:\n",
    "    best_model_name = f\"{best_choice}\"\n",
    "    model_path = os.path.join(MODEL_DIR, f\"{best_model_name}_pipeline.joblib\")\n",
    "    try:\n",
    "        joblib.dump(best_model, model_path)\n",
    "        print('Saved best pipeline to', model_path)\n",
    "    except Exception as e:\n",
    "        print('Failed to save best pipeline:', e)\n",
    "else:\n",
    "    print('Skipping save; no model available.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396e846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# Final summary: standardized metrics table and saving a final CSV\n",
    "try:\n",
    "    if 'results_df' not in globals():\n",
    "        results_df = pd.DataFrame(RESULTS)\n",
    "    if 'rmse' in results_df.columns:\n",
    "        results_df_sorted = results_df.sort_values('rmse')\n",
    "        display(results_df_sorted)\n",
    "        metrics_out_file = os.path.join(MODEL_DIR, 'final_metrics_summary.csv')\n",
    "        results_df_sorted.to_csv(metrics_out_file, index=False)\n",
    "        print('Saved final metrics summary to', metrics_out_file)\n",
    "    else:\n",
    "        print('No \"rmse\" column in results_df; raw RESULTS is shown:')\n",
    "        display(results_df)\n",
    "except Exception as e:\n",
    "    print('Failed to create final summary:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f7d59b",
   "metadata": {},
   "source": [
    "## How to run this notebook (Tips & Best Practices)\n",
    "\n",
    "**Local GPU (recommended for XGBoost/LightGBM):** Install GPU drivers and ensure `nvidia-smi` is available. XGBoost uses `tree_method='gpu_hist'` when GPU detected.\n",
    "\n",
    "**Downsample:** If running locally with limited resources, set `DOWNSAMPLE=True` and `MAX_ROWS` in the first section to quickly iterate.\n",
    "\n",
    "**Experimentation:** Long hyperparameter tuning should be run in a compute environment or using job scheduling. Use `optuna` or `Ray Tune` for distributed tuning.\n",
    "\n",
    "**Deployment:** Save the `best_model` as a `joblib` object in `models/` and create a simple API wrapper (Flask/FastAPI) for inference. Add monitoring for model drift and data schema changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e794e60f",
   "metadata": {},
   "source": [
    "# ---\n",
    "\n",
    "## Conclusion & Next Steps\n",
    "\n",
    "- Mô hình XGBoost (tuned) thường là lựa chọn mạnh mẽ cho bài toán này khi đo bằng RMSE. Các bước tiếp theo:\n",
    "  1. Tiếp tục tuning với Optuna hoặc Bayesian optimization để tăng hiệu năng.\n",
    "  2. Thêm feature importance và SHAP để giải thích những dự đoán có sai số cao.\n",
    "  3. Xây dựng pipeline triển khai (API/Batch) và theo dõi chất lượng mô hình theo thời gian (drift).\n",
    "  4. Đánh giá tác động của việc cắt ngọn (winsorization) và thử nghiệm dùng Huber loss hoặc Pinball loss (quantile regression) nếu cần.\n",
    "\n",
    "- Lưu ý: Hãy kiểm tra kỹ các cột tên (SCHEDULED/ACTUAL/ID) trước khi chạy notebook trên toàn bộ dữ liệu.\n",
    "\n",
    "Cảm ơn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3235e0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... (previous part unchanged) ...\n",
    "# simple rolling mean based on SCHEDULED_DT index\n",
    "route_col = _get_route_column(train_df)\n",
    "if 'SCHEDULED_DT' in train_df.columns:\n",
    "    # handle rows with valid datetime only\n",
    "    mask_valid_dt = train_df['SCHEDULED_DT'].notna()\n",
    "    if 'TARGET' in train_df.columns and mask_valid_dt.any():\n",
    "        temp = train_df.loc[mask_valid_dt].copy()\n",
    "        temp = temp.sort_values(['SCHEDULED_DT'] if route_col is None else [route_col, 'SCHEDULED_DT'])\n",
    "        if route_col is not None:\n",
    "            temp['ROLL_MEAN_7D'] = temp.groupby(route_col)['TARGET'].transform(lambda x: x.rolling('7D').mean())\n",
    "        else:\n",
    "            temp['ROLL_MEAN_7D'] = temp['TARGET'].rolling('7D').mean()\n",
    "        # align back\n",
    "        train_df['ROLL_MEAN_7D'] = pd.NA\n",
    "        train_df.loc[temp.index, 'ROLL_MEAN_7D'] = temp['ROLL_MEAN_7D']\n",
    "    else:\n",
    "        train_df['ROLL_MEAN_7D'] = np.nan\n",
    "    train_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6185d1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... (previous part unchanged) ...\n",
    "# simple rolling mean based on SCHEDULED_DT index\n",
    "route_col = _get_route_column(df)\n",
    "if 'SCHEDULED_DT' in df.columns and 'TARGET' in df.columns:\n",
    "    df['ROLL_MEAN_7D'] = np.nan\n",
    "    if route_col is not None:\n",
    "        for name, group in df.groupby(route_col):\n",
    "            try:\n",
    "                sub = group.dropna(subset=['SCHEDULED_DT'])\n",
    "                if sub.empty:\n",
    "                    continue\n",
    "                sub = sub.sort_values('SCHEDULED_DT')\n",
    "                sub_index = sub.index\n",
    "                sub_indexed = sub.set_index('SCHEDULED_DT')\n",
    "                # compute rolling 7D per group\n",
    "                sub_indexed['ROLL_MEAN_7D'] = sub_indexed['TARGET'].rolling('7D').mean()\n",
    "                # map back\n",
    "                df.loc[sub_index, 'ROLL_MEAN_7D'] = sub_indexed['ROLL_MEAN_7D'].values\n",
    "            except Exception:\n",
    "                continue\n",
    "    else:\n",
    "        # global rolling when no route column\n",
    "        df = df.sort_values('SCHEDULED_DT')\n",
    "        df.index = pd.to_datetime(df['SCHEDULED_DT'])\n",
    "        df['ROLL_MEAN_7D'] = df['TARGET'].rolling('7D').mean()\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "else:\n",
    "    df['ROLL_MEAN_7D'] = df['TARGET'].median() if 'TARGET' in df.columns else 0\n",
    "# Reset index sanity\n",
    "if 'SCHEDULED_DT' in df.columns and df.index.name == 'SCHEDULED_DT':\n",
    "    df.reset_index(inplace=True)\n",
    "# ... rest unchanged ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
