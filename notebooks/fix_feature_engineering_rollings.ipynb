{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b99909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 1: (Re)import & Setup: safe copies, logging and helper reload\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "# Use the existing train_df if it is in the main notebook's globals; otherwise, try load the processed CSV\n",
    "try:\n",
    "    train_df\n",
    "except NameError:\n",
    "    TRAIN_PATH = r\"D:\\MSE\\5. Data Mining\\railway-delay\\data\\processed\\merged_train_data.csv\"\n",
    "    if os.path.exists(TRAIN_PATH):\n",
    "        train_df = pd.read_csv(TRAIN_PATH, parse_dates=True)\n",
    "    else:\n",
    "        # Create an empty sample to run unit tests later\n",
    "        train_df = pd.DataFrame()\n",
    "\n",
    "# Create a working copy for debug so we don't affect global state accidentally\n",
    "df = train_df.copy()\n",
    "print('Working df shape:', df.shape)\n",
    "print('Columns:', df.columns.tolist())\n",
    "\n",
    "# Redefine / show our helper definitions (we'll override later with robust versions if needed)\n",
    "\n",
    "# Minimal logging\n",
    "def _log(msg):\n",
    "    print(f\"[fix_feature_engineering] {msg}\")\n",
    "\n",
    "_log('Setup done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78315de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 2: Inspect route/time columns and reproduce KeyError (safe diagnostics)\n",
    "\n",
    "# Candidate route columns\n",
    "route_candidates = ['STATION_ID', 'ROUTE_ID', 'TRAIN_ID', 'TRAIN_NUMBER', 'ROUTE', 'STATION']\n",
    "route_col = None\n",
    "for c in route_candidates:\n",
    "    if c in df.columns:\n",
    "        route_col = c\n",
    "        break\n",
    "\n",
    "_log(f'route detected: {route_col}')\n",
    "_log(f\"index names: {df.index.names}\")\n",
    "\n",
    "# Candidate schedule/time column search\n",
    "sched_candidates = ['SCHEDULED_DT', 'SCHEDULED_DATE', 'SCHEDULED_TIME', 'SCHEDULED']\n",
    "schedule_col = None\n",
    "for c in sched_candidates:\n",
    "    if c in df.columns:\n",
    "        schedule_col = c\n",
    "        break\n",
    "\n",
    "_log(f'schedule column: {schedule_col}')\n",
    "\n",
    "# Show sample values for route_col and schedule_col\n",
    "if route_col is not None:\n",
    "    _log(f\"Unique sample for {route_col}: {df[route_col].unique()[:5] if route_col in df.columns else 'Route not in columns'}\")\n",
    "else:\n",
    "    _log('No route column present')\n",
    "\n",
    "if schedule_col is not None:\n",
    "    _log(f\"Schedule dtype: {df[schedule_col].dtype}\")\n",
    "else:\n",
    "    _log('No schedule column present')\n",
    "\n",
    "# Try to reproduce the error in a try/except block using same logic as original code\n",
    "try:\n",
    "    # mimic the original approach: set index\n",
    "    if schedule_col is None:\n",
    "        raise KeyError('SCHEDULED_DT missing for demonstration')\n",
    "    df_test = df.copy()\n",
    "    df_test[schedule_col] = pd.to_datetime(df_test[schedule_col], errors='coerce')\n",
    "    df_test.set_index(schedule_col, inplace=True)\n",
    "    # If route_col is None, this should raise if the code mistakenly attempts to groupby None\n",
    "    _log('Attempting original grouping approach')\n",
    "    df_test['ROLLING_MEAN_DELAY_7D'] = df_test.groupby(route_col)['TARGET'].transform(lambda x: x.rolling('7D').mean())\n",
    "    _log('Original approach succeeded (unexpected)')\n",
    "except Exception as e:\n",
    "    _log('Original approach produced exception:')\n",
    "    _log(str(e))\n",
    "    _log('Diagnostics:')\n",
    "    _log('df columns: ' + str(df.columns.tolist()))\n",
    "    _log('df index name: ' + str(df.index.name))\n",
    "    _log('route_col used: ' + str(route_col))\n",
    "    if route_col is not None and route_col not in df.columns:\n",
    "        _log(f\"Note: route_col {route_col} not present in df.columns; maybe it is an index? df.index.names={df.index.names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a748519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 3: Robust compute_rolling_features (fixed implementation)\n",
    "\n",
    "# We'll implement a robust rolling function that handles:\n",
    "# - schedule_col missing -> skip\n",
    "# - route_col present as column -> groupby column + time-based rolling\n",
    "# - route_col present as index level -> groupby(level=route_col)\n",
    "# - route_col not present -> global rolling on time index\n",
    "\n",
    "\n",
    "def compute_rolling_features_safe(df_in, target_col='TARGET', schedule_col='SCHEDULED_DT', candidates=None, w7='7D', w30='30D'):\n",
    "    df = df_in.copy()\n",
    "    if candidates is None:\n",
    "        candidates = ['STATION_ID', 'ROUTE_ID', 'TRAIN_ID', 'TRAIN_NUMBER', 'ROUTE', 'STATION']\n",
    "\n",
    "    def _get_route_col_local(df):\n",
    "        for c in candidates:\n",
    "            if c in df.columns:\n",
    "                return c\n",
    "        return None\n",
    "\n",
    "    route_col_local = _get_route_col_local(df)\n",
    "\n",
    "    # Ensure schedule_col exists and is datetime\n",
    "    if schedule_col not in df.columns:\n",
    "        _log(f\"{schedule_col} missing; skipping rolling features and filling with median\")\n",
    "        df['ROLLING_MEAN_DELAY_7D'] = df[target_col].median() if target_col in df.columns else np.nan\n",
    "        df['ROLLING_MEAN_DELAY_30D'] = df[target_col].median() if target_col in df.columns else np.nan\n",
    "        return df\n",
    "\n",
    "    df[schedule_col] = pd.to_datetime(df[schedule_col], errors='coerce')\n",
    "\n",
    "    if route_col_local is not None and route_col_local in df.columns:\n",
    "        # We can do groupby route_col + rolling on time index\n",
    "        df = df.sort_values([route_col_local, schedule_col])\n",
    "        try:\n",
    "            # Ensure index is schedule\n",
    "            tmp = df.set_index(schedule_col)\n",
    "            tmp['ROLLING_MEAN_DELAY_7D'] = tmp.groupby(route_col_local)[target_col].transform(lambda x: x.rolling(w7).mean())\n",
    "            tmp['ROLLING_MEAN_DELAY_30D'] = tmp.groupby(route_col_local)[target_col].transform(lambda x: x.rolling(w30).mean())\n",
    "            df['ROLLING_MEAN_DELAY_7D'] = tmp['ROLLING_MEAN_DELAY_7D'].values\n",
    "            df['ROLLING_MEAN_DELAY_30D'] = tmp['ROLLING_MEAN_DELAY_30D'].values\n",
    "        except Exception as e:\n",
    "            _log('groupby-rolling by route_col raised exception, falling back to per-group manual compute: ' + str(e))\n",
    "            df['ROLLING_MEAN_DELAY_7D'] = np.nan\n",
    "            df['ROLLING_MEAN_DELAY_30D'] = np.nan\n",
    "            for name, group in df.groupby(route_col_local):\n",
    "                try:\n",
    "                    sub = group.sort_values(schedule_col)\n",
    "                    sub_index = sub.index\n",
    "                    sub_indexed = sub.set_index(schedule_col)\n",
    "                    sub_indexed['ROLLING_MEAN_DELAY_7D'] = sub_indexed[target_col].rolling(w7).mean()\n",
    "                    sub_indexed['ROLLING_MEAN_DELAY_30D'] = sub_indexed[target_col].rolling(w30).mean()\n",
    "                    df.loc[sub_index, 'ROLLING_MEAN_DELAY_7D'] = sub_indexed['ROLLING_MEAN_DELAY_7D'].values\n",
    "                    df.loc[sub_index, 'ROLLING_MEAN_DELAY_30D'] = sub_indexed['ROLLING_MEAN_DELAY_30D'].values\n",
    "                except Exception:\n",
    "                    continue\n",
    "    else:\n",
    "        # No route column in columns; try route as index level\n",
    "        idx_names = df.index.names if df.index is not None else []\n",
    "        route_index_level = None\n",
    "        for c in candidates:\n",
    "            if c in idx_names:\n",
    "                route_index_level = c\n",
    "                break\n",
    "        df = df.sort_values(schedule_col)\n",
    "        df_indexed = df.set_index(schedule_col)\n",
    "        if route_index_level is not None:\n",
    "            try:\n",
    "                df_indexed['ROLLING_MEAN_DELAY_7D'] = df_indexed.groupby(level=route_index_level)[target_col].transform(lambda x: x.rolling(w7).mean())\n",
    "                df_indexed['ROLLING_MEAN_DELAY_30D'] = df_indexed.groupby(level=route_index_level)[target_col].transform(lambda x: x.rolling(w30).mean())\n",
    "                df['ROLLING_MEAN_DELAY_7D'] = df_indexed['ROLLING_MEAN_DELAY_7D'].values\n",
    "                df['ROLLING_MEAN_DELAY_30D'] = df_indexed['ROLLING_MEAN_DELAY_30D'].values\n",
    "            except Exception as e:\n",
    "                _log('index-level groupby failing: ' + str(e) + ' -> fallback to global time rolling')\n",
    "                df_indexed['ROLLING_MEAN_DELAY_7D'] = df_indexed[target_col].rolling(w7).mean()\n",
    "                df_indexed['ROLLING_MEAN_DELAY_30D'] = df_indexed[target_col].rolling(w30).mean()\n",
    "                df['ROLLING_MEAN_DELAY_7D'] = df_indexed['ROLLING_MEAN_DELAY_7D'].values\n",
    "                df['ROLLING_MEAN_DELAY_30D'] = df_indexed['ROLLING_MEAN_DELAY_30D'].values\n",
    "        else:\n",
    "            # global rolling\n",
    "            df_indexed['ROLLING_MEAN_DELAY_7D'] = df_indexed[target_col].rolling(w7).mean()\n",
    "            df_indexed['ROLLING_MEAN_DELAY_30D'] = df_indexed[target_col].rolling(w30).mean()\n",
    "            df['ROLLING_MEAN_DELAY_7D'] = df_indexed['ROLLING_MEAN_DELAY_7D'].values\n",
    "            df['ROLLING_MEAN_DELAY_30D'] = df_indexed['ROLLING_MEAN_DELAY_30D'].values\n",
    "\n",
    "    # Fill NaNs with group median if possible or global median fallback\n",
    "    try:\n",
    "        if route_col_local is not None and route_col_local in df.columns:\n",
    "            df['ROLLING_MEAN_DELAY_7D'] = df['ROLLING_MEAN_DELAY_7D'].fillna(df.groupby(route_col_local)[target_col].transform('median'))\n",
    "            df['ROLLING_MEAN_DELAY_30D'] = df['ROLLING_MEAN_DELAY_30D'].fillna(df.groupby(route_col_local)[target_col].transform('median'))\n",
    "        else:\n",
    "            df['ROLLING_MEAN_DELAY_7D'] = df['ROLLING_MEAN_DELAY_7D'].fillna(df[target_col].median() if target_col in df.columns else np.nan)\n",
    "            df['ROLLING_MEAN_DELAY_30D'] = df['ROLLING_MEAN_DELAY_30D'].fillna(df[target_col].median() if target_col in df.columns else np.nan)\n",
    "    except Exception:\n",
    "        df['ROLLING_MEAN_DELAY_7D'] = df['ROLLING_MEAN_DELAY_7D'].fillna(df[target_col].median() if target_col in df.columns else np.nan)\n",
    "        df['ROLLING_MEAN_DELAY_30D'] = df['ROLLING_MEAN_DELAY_30D'].fillna(df[target_col].median() if target_col in df.columns else np.nan)\n",
    "\n",
    "    return df\n",
    "\n",
    "_log('compute_rolling_features_safe defined')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca63a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 4: Improve compute_prev_delay (safe grouping + index handling)\n",
    "\n",
    "def compute_prev_delay_safe(df_in, target_col='TARGET', schedule_col='SCHEDULED_DT', candidates=None, default_fill=-1):\n",
    "    df = df_in.copy()\n",
    "    if candidates is None:\n",
    "        candidates = ['TRAIN_ID','STATION_ID','ROUTE_ID','TRAIN_NUMBER','ROUTE','STATION']\n",
    "\n",
    "    def _get_route_local(df):\n",
    "        for c in candidates:\n",
    "            if c in df.columns:\n",
    "                return c\n",
    "        return None\n",
    "\n",
    "    route_local = _get_route_local(df)\n",
    "\n",
    "    if schedule_col not in df.columns:\n",
    "        _log(f\"{schedule_col} missing; PREV_DELAY will be set to default {default_fill}\")\n",
    "        df['PREV_DELAY'] = default_fill\n",
    "        return df\n",
    "\n",
    "    # Ensure schedule_col is datetime\n",
    "    df[schedule_col] = pd.to_datetime(df[schedule_col], errors='coerce')\n",
    "\n",
    "    # Sort by route and schedule\n",
    "    if route_local is not None and route_local in df.columns:\n",
    "        df = df.sort_values([route_local, schedule_col])\n",
    "        try:\n",
    "            df['PREV_DELAY'] = df.groupby(route_local)[target_col].shift(1)\n",
    "        except Exception as e:\n",
    "            _log('groupby shift failed with exception: ' + str(e) + ' -> Attempting per-group fallback')\n",
    "            df['PREV_DELAY'] = np.nan\n",
    "            for name, group in df.groupby(route_local):\n",
    "                sub = group.sort_values(schedule_col)\n",
    "                df.loc[sub.index, 'PREV_DELAY'] = sub[target_col].shift(1).values\n",
    "    else:\n",
    "        # route not present in columns, check if index has a route level\n",
    "        idx_names = df.index.names if df.index is not None else []\n",
    "        route_index_level = None\n",
    "        for c in candidates:\n",
    "            if c in idx_names:\n",
    "                route_index_level = c\n",
    "                break\n",
    "        if route_index_level is not None:\n",
    "            df = df.sort_values(schedule_col)\n",
    "            try:\n",
    "                df['PREV_DELAY'] = df.groupby(level=route_index_level)[target_col].shift(1)\n",
    "            except Exception as e:\n",
    "                _log('groupby by index failed: ' + str(e) + ' -> fallback to global shift')\n",
    "                df = df.sort_values(schedule_col)\n",
    "                df['PREV_DELAY'] = df[target_col].shift(1)\n",
    "        else:\n",
    "            # no route info -> global shift by schedule\n",
    "            df = df.sort_values(schedule_col)\n",
    "            df['PREV_DELAY'] = df[target_col].shift(1)\n",
    "\n",
    "    # Fill PREV_DELAY NaNs with median if possible\n",
    "    try:\n",
    "        if route_local is not None and route_local in df.columns:\n",
    "            df['PREV_DELAY'] = df['PREV_DELAY'].fillna(df.groupby(route_local)[target_col].transform('median'))\n",
    "        else:\n",
    "            df['PREV_DELAY'] = df['PREV_DELAY'].fillna(df[target_col].median() if target_col in df.columns else default_fill)\n",
    "    except Exception:\n",
    "        df['PREV_DELAY'] = df['PREV_DELAY'].fillna(default_fill)\n",
    "\n",
    "    # Cast to numeric\n",
    "    df['PREV_DELAY'] = pd.to_numeric(df['PREV_DELAY'], errors='coerce').fillna(default_fill)\n",
    "    return df\n",
    "\n",
    "_log('compute_prev_delay_safe defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ecfe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 5: Apply fixes to train_df & validate columns present\n",
    "\n",
    "# We'll try to use our compute_prev_delay_safe & compute_rolling_features_safe on df (working copy)\n",
    "\n",
    "_log('Applying compute_prev_delay_safe...')\n",
    "try:\n",
    "    df = compute_prev_delay_safe(df)\n",
    "    _log('PREV_DELAY stats:')\n",
    "    _log(str(df['PREV_DELAY'].describe()))\n",
    "except Exception as e:\n",
    "    _log('compute_prev_delay_safe failed: ' + str(e))\n",
    "\n",
    "_log('Applying compute_rolling_features_safe...')\n",
    "try:\n",
    "    df = compute_rolling_features_safe(df)\n",
    "    _log('ROLLING_MEAN_DELAY_7D stats:')\n",
    "    _log(str(df['ROLLING_MEAN_DELAY_7D'].describe()))\n",
    "    _log('ROLLING_MEAN_DELAY_30D stats:')\n",
    "    _log(str(df['ROLLING_MEAN_DELAY_30D'].describe()))\n",
    "except Exception as e:\n",
    "    _log('compute_rolling_features_safe failed: ' + str(e))\n",
    "\n",
    "# sanity checks\n",
    "assert 'PREV_DELAY' in df.columns, 'PREV_DELAY missing'\n",
    "assert 'ROLLING_MEAN_DELAY_7D' in df.columns, 'ROLLING_MEAN_DELAY_7D missing'\n",
    "assert 'ROLLING_MEAN_DELAY_30D' in df.columns, 'ROLLING_MEAN_DELAY_30D missing'\n",
    "\n",
    "# sample display for routes (if present), else global head\n",
    "if any(c in df.columns for c in ['TRAIN_ID', 'STATION_ID', 'ROUTE_ID']):\n",
    "    rc = next((c for c in ['TRAIN_ID', 'STATION_ID', 'ROUTE_ID'] if c in df.columns), None)\n",
    "    _log('show sample group for: ' + rc)\n",
    "    display(df.loc[df[rc].notna()].head(8)[['TARGET', 'PREV_DELAY', 'ROLLING_MEAN_DELAY_7D', 'ROLLING_MEAN_DELAY_30D']])\n",
    "else:\n",
    "    display(df.head(10)[['TARGET', 'PREV_DELAY', 'ROLLING_MEAN_DELAY_7D', 'ROLLING_MEAN_DELAY_30D']])\n",
    "\n",
    "_log('Application done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a32e6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 7: Edge cases & fallback strategies for missing columns or index-based grouping\n",
    "# Additional checks and safer conversions\n",
    "\n",
    "# Case: route column present but due to dtype differences groupby raised an error. Cast route columns to str to avoid issues\n",
    "\n",
    "def cast_route_to_string(df_in, candidates=None):\n",
    "    df = df_in.copy()\n",
    "    if candidates is None:\n",
    "        candidates = ['STATION_ID', 'ROUTE_ID', 'TRAIN_ID', 'TRAIN_NUMBER', 'ROUTE', 'STATION']\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            try:\n",
    "                df[c] = df[c].astype(str)\n",
    "            except Exception:\n",
    "                continue\n",
    "    return df\n",
    "\n",
    "# Example to protect the pipeline: apply type casting when needed\n",
    "try:\n",
    "    df_safe = cast_route_to_string(df)\n",
    "    _log('cast_route_to_string applied')\n",
    "except Exception as e:\n",
    "    _log('casting failed: ' + str(e))\n",
    "\n",
    "# If index is multi-level with non-string values: cast index levels to string for grouping convenience\n",
    "if isinstance(df_safe.index, pd.MultiIndex):\n",
    "    try:\n",
    "        df_safe.index = df_safe.index.set_levels([lev.astype(str) for lev in df_safe.index.levels])\n",
    "        _log('MultiIndex levels cast to str')\n",
    "    except Exception as e:\n",
    "        _log('Failed to cast MultiIndex levels: ' + str(e))\n",
    "\n",
    "_log('Edge case strategies tested')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047a985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 8: Integrate corrected helpers into pipeline and save results\n",
    "# This cell shows how to use the safe helpers and optionally replace existing helpers in the main notebook.\n",
    "# If you want to persist these helpers to a utility module, create a file and import in other notebooks.\n",
    "\n",
    "# Example: apply to the main train_df and keep the original 'train_df' updated\n",
    "try:\n",
    "    train_df = compute_prev_delay_safe(train_df)\n",
    "    train_df = compute_rolling_features_safe(train_df)\n",
    "    _log('train_df updated with safe prev_delay & rolling features')\n",
    "except Exception as e:\n",
    "    _log('Applying to global train_df failed: ' + str(e))\n",
    "\n",
    "# Final checks\n",
    "try:\n",
    "    print('Columns now include:', [c for c in ['PREV_DELAY', 'ROLLING_MEAN_DELAY_7D', 'ROLLING_MEAN_DELAY_30D'] if c in train_df.columns])\n",
    "    print('Sample:')\n",
    "    display(train_df[['TARGET','PREV_DELAY','ROLLING_MEAN_DELAY_7D','ROLLING_MEAN_DELAY_30D']].head())\n",
    "except Exception as e:\n",
    "    _log('Cannot display final sample: ' + str(e))\n",
    "\n",
    "# Optionally, replace the util function definitions in this repo: write to file 'src/utils/feature_helpers.py' (not overwriting original functions here)\n",
    "# To keep changes minimal, consider copy-pasting these functions into the utilities file (or import them here)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
